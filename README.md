# Fine-tuning PhoBERT cho PhÃ¢n tÃ­ch Cáº£m xÃºc Tiáº¿ng Viá»‡t (3 nhÃ£n)

ÄÃ¢y lÃ  project fine-tuning mÃ´ hÃ¬nh **`vinai/phobert-base`**, má»™t mÃ´ hÃ¬nh Transformer SOTA cho Tiáº¿ng Viá»‡t, cho nhiá»‡m vá»¥ **PhÃ¢n loáº¡i Cáº£m xÃºc 3 nhÃ£n**: TÃ­ch cá»±c (POS), TiÃªu cá»±c (NEG), vÃ  Trung tÃ­nh (NEU).

MÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ trÃªn bá»™ dá»¯ liá»‡u dá»±a trÃªn VLSP (Ä‘Æ°á»£c cung cáº¥p dÆ°á»›i dáº¡ng file CSV trong thÆ° má»¥c `data/`) vÃ  Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ **F1-score (weighted) khoáº£ng 71%** trÃªn táº­p kiá»ƒm thá»­ (test set).

## ğŸ“Š Káº¿t quáº£ Ná»•i báº­t

* **MÃ´ hÃ¬nh ná»n:** `vinai/phobert-base` (Sá»­ dá»¥ng `AutoModelForSequenceClassification` tá»« Hugging Face Transformers).
* **Táº­p dá»¯ liá»‡u:** Dá»¯ liá»‡u CSV cá»¥c bá»™ (`train.csv`, `val.csv`, `test.csv`) vá»›i 3 nhÃ£n (`POS`, `NEG`, `NEU`).
* **Káº¿t quáº£ (trÃªn táº­p Test):**
    * **Loss:** ~0.69
    * **F1-score (Weighted):** **~0.71**

MÃ´ hÃ¬nh cho tháº¥y kháº£ nÄƒng phÃ¢n loáº¡i tá»‘t trÃªn cÃ¡c vÃ­ dá»¥ thá»±c táº¿:

* `"Phim nÃ y hay tháº­t sá»±, ná»™i dung sÃ¢u sáº¯c."` -> **POS (Score: ~0.93)**
* `"Shop lÃ m Äƒn chÃ¡n quÃ¡, giao hÃ ng thÃ¬ lÃ¢u, sáº£n pháº©m thÃ¬ vá»¡."` -> **NEG (Score: ~0.88)**
* `"Äiá»‡n thoáº¡i nÃ y sáº½ ra máº¯t vÃ o thÃ¡ng 12 tá»›i."` -> **NEU (Score: ~0.51)**

## ğŸš€ CÃ i Ä‘áº·t vÃ  MÃ´i trÆ°á»ng

1.  **Clone repository:**
    ```bash
    git clone [https://github.com/thien2603/PhoBERT-Sentiment-Analysis.git](https://github.com/thien2603/PhoBERT-Sentiment-Analysis.git)
    cd PhoBERT-Sentiment-Analysis
    ```

2.  **Táº¡o mÃ´i trÆ°á»ng áº£o** (khuyáº¿n khÃ­ch Ä‘á»ƒ quáº£n lÃ½ dependencies):
    ```bash
    python -m venv venv
    ```
    * **Linux/macOS:**
        ```bash
        source venv/bin/activate
        ```
    * **Windows:**
        ```bash
        venv\Scripts\activate
        ```

3.  **CÃ i Ä‘áº·t thÆ° viá»‡n:** CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t Ä‘Æ°á»£c liá»‡t kÃª trong `requirements.txt`.
    ```bash
    pip install -r requirements.txt
    ```
    *(Äáº£m báº£o báº¡n Ä‘Ã£ kÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o trÆ°á»›c khi cháº¡y lá»‡nh nÃ y).*

## â–¶ï¸ CÃ¡ch thá»±c thi

1.  **Dá»¯ liá»‡u:** Dá»¯ liá»‡u huáº¥n luyá»‡n (`train.csv`), kiá»ƒm thá»­ (`val.csv`), vÃ  Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng (`test.csv`) Ä‘Ã£ cÃ³ sáºµn trong thÆ° má»¥c `data/`.
2.  **Huáº¥n luyá»‡n & ÄÃ¡nh giÃ¡:** Má»Ÿ vÃ  cháº¡y toÃ n bá»™ cÃ¡c Ã´ code trong file Jupyter Notebook `train.ipynb` (hoáº·c tÃªn file notebook cá»§a báº¡n).
    * QuÃ¡ trÃ¬nh nÃ y sáº½ tá»± Ä‘á»™ng táº£i dá»¯ liá»‡u, tiá»n xá»­ lÃ½, huáº¥n luyá»‡n model, vÃ  Ä‘Ã¡nh giÃ¡ trÃªn táº­p test.
    * Model fine-tuned tá»‘t nháº¥t cÃ¹ng vá»›i tokenizer sáº½ Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c `./results_sentiment_3label/`. (ThÆ° má»¥c nÃ y Ä‘Æ°á»£c `.gitignore` bá» qua).
3.  **Thá»­ nghiá»‡m:** Pháº§n cuá»‘i cÃ¹ng cá»§a notebook (`SECTION 4`) sáº½ táº£i model Ä‘Ã£ lÆ°u vÃ  sá»­ dá»¥ng `pipeline` Ä‘á»ƒ báº¡n thá»­ nghiá»‡m dá»± Ä‘oÃ¡n trÃªn cÃ¡c cÃ¢u vÄƒn má»›i.

## ğŸ› ï¸ Quy trÃ¬nh Thá»±c hiá»‡n

Notebook `train.ipynb` thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:

1.  **Táº£i vÃ  Chuáº©n bá»‹ Dá»¯ liá»‡u (`SECTION 1`):**
    * Sá»­ dá»¥ng `load_dataset` cá»§a Hugging Face `datasets` Ä‘á»ƒ Ä‘á»c 3 file `.csv` tá»« thÆ° má»¥c `data/`.
    * Ãnh xáº¡ (map) cÃ¡c nhÃ£n dáº¡ng chuá»—i (`POS`, `NEG`, `NEU`) sang dáº¡ng sá»‘ nguyÃªn (`2`, `0`, `1`) sá»­ dá»¥ng dictionary `label2id`.
    * Táº£i `AutoTokenizer` tÆ°Æ¡ng á»©ng vá»›i `vinai/phobert-base`.
    * Äá»‹nh nghÄ©a hÃ m `preprocess_function` Ä‘á»ƒ token hÃ³a vÄƒn báº£n (padding/truncation Ä‘áº¿n `max_length=128`).
    * Ãp dá»¥ng tokenization cho toÃ n bá»™ dataset báº±ng phÆ°Æ¡ng thá»©c `.map()`.

2.  **Táº£i Model vÃ  Cáº¥u hÃ¬nh Huáº¥n luyá»‡n (`SECTION 2`):**
    * Táº£i `AutoModelForSequenceClassification` tá»« `vinai/phobert-base`, cáº¥u hÃ¬nh cho 3 nhÃ£n vÃ  Ä‘Ã­nh kÃ¨m `id2label`, `label2id`.
    * Thiáº¿t láº­p `TrainingArguments`, bao gá»“m thÆ° má»¥c output, sá»‘ epochs, batch size, cÃ¡c tham sá»‘ Ä‘Ã¡nh giÃ¡/lÆ°u trá»¯ (`do_eval`, `save_steps`), vÃ  táº¯t logging lÃªn `wandb` (`report_to="none"`).
    * Äá»‹nh nghÄ©a hÃ m `compute_metrics` sá»­ dá»¥ng `evaluate.load("f1")` vá»›i `average="weighted"` Ä‘á»ƒ tÃ­nh F1-score trong quÃ¡ trÃ¬nh Ä‘Ã¡nh giÃ¡.
    * Khá»Ÿi táº¡o `Trainer` vá»›i model, arguments, datasets (train vÃ  validation), vÃ  hÃ m compute_metrics.

3.  **Huáº¥n luyá»‡n vÃ  ÄÃ¡nh giÃ¡ (`SECTION 3`):**
    * Gá»i `trainer.train()` Ä‘á»ƒ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh fine-tuning.
    * Sau khi huáº¥n luyá»‡n, lÆ°u model vÃ  tokenizer vÃ o thÆ° má»¥c output báº±ng `trainer.save_model()` vÃ  `tokenizer.save_pretrained()`.
    * Gá»i `trainer.evaluate()` trÃªn táº­p `test` Ä‘á»ƒ cÃ³ káº¿t quáº£ Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng trÃªn dá»¯ liá»‡u unseen.

4.  **Thá»­ nghiá»‡m (Inference) (`SECTION 4`):**
    * Táº£i láº¡i model vÃ  tokenizer Ä‘Ã£ lÆ°u tá»« thÆ° má»¥c output má»™t cÃ¡ch tÆ°á»ng minh.
    * Táº¡o má»™t `pipeline("text-classification")` tá»« model vÃ  tokenizer Ä‘Ã£ táº£i.
    * Thá»­ nghiá»‡m pipeline vá»›i cÃ¡c cÃ¢u vÃ­ dá»¥ Ä‘á»ƒ kiá»ƒm tra kháº£ nÄƒng dá»± Ä‘oÃ¡n cá»§a model.

## ğŸ’» CÃ´ng nghá»‡ sá»­ dá»¥ng

* Python 3.x
* PyTorch
* Hugging Face Transformers
* Hugging Face Datasets
* Hugging Face Evaluate
* NumPy
